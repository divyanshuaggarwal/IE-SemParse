{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA15RLpOYPm5",
        "outputId": "74b809d3-4545-4b1f-8ca8-d8d8537a7da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taE4-6Rm5Cmr",
        "outputId": "33acb91a-ecaf-46e8-b9ff-088109690248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'indicTrans'...\n",
            "remote: Enumerating objects: 585, done.\u001b[K\n",
            "remote: Counting objects: 100% (288/288), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 585 (delta 210), reused 229 (delta 173), pack-reused 297\u001b[K\n",
            "Receiving objects: 100% (585/585), 1.54 MiB | 6.15 MiB/s, done.\n",
            "Resolving deltas: 100% (337/337), done.\n",
            "/content/indicTrans\n",
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 1325, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 1325 (delta 91), reused 82 (delta 82), pack-reused 1218\u001b[K\n",
            "Receiving objects: 100% (1325/1325), 9.55 MiB | 7.04 MiB/s, done.\n",
            "Resolving deltas: 100% (701/701), done.\n",
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 139 (delta 2), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (139/139), 149.77 MiB | 21.87 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "Cloning into 'subword-nmt'...\n",
            "remote: Enumerating objects: 590, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 590 (delta 3), reused 4 (delta 1), pack-reused 576\u001b[K\n",
            "Receiving objects: 100% (590/590), 245.03 KiB | 10.21 MiB/s, done.\n",
            "Resolving deltas: 100% (352/352), done.\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# clone the repo for running evaluation\n",
        "!git clone https://github.com/AI4Bharat/indicTrans.git\n",
        "%cd indicTrans\n",
        "# clone requirements repositories\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!git clone https://github.com/rsennrich/subword-nmt.git\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary libraries\n",
        "!pip install sacremoses pandas mock sacrebleu tensorboardX pyarrow indic-nlp-library\n",
        "! pip install mosestokenizer subword-nmt\n",
        "# Install fairseq from source\n",
        "!git clone https://github.com/pytorch/fairseq.git\n",
        "%cd fairseq\n",
        "# !git checkout da9eaba12d82b9bfc1442f0e2c6fc1b895f4d35d\n",
        "!pip install  --use-feature=in-tree-build ./\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gWSDoY-YNJp",
        "outputId": "4683597c-0638-4072-b79a-9e8f5ade002b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 11.9 MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 76.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (6.0.1)\n",
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.81-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.64.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Collecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Collecting sphinx-rtd-theme\n",
            "  Downloading sphinx_rtd_theme-1.0.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 55.9 MB/s \n",
            "\u001b[?25hCollecting sphinx-argparse\n",
            "  Downloading sphinx_argparse-0.3.1-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx-argparse->indic-nlp-library) (1.8.6)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (21.3)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (57.4.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.12)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.6.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.2.4)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.17.1)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.0.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.0.8)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.5)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=6ef72efaf573519a51e0aad34bc0cdf9186b4a59879c6be3a98f767a66b6b250\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sphinx-rtd-theme, sphinx-argparse, portalocker, morfessor, colorama, tensorboardX, sacremoses, sacrebleu, mock, indic-nlp-library\n",
            "Successfully installed colorama-0.4.4 indic-nlp-library-0.81 mock-4.0.3 morfessor-2.0.6 portalocker-2.4.0 sacrebleu-2.0.0 sacremoses-0.0.53 sphinx-argparse-0.3.1 sphinx-rtd-theme-1.0.0 tensorboardX-2.5\n",
            "Collecting mosestokenizer\n",
            "  Downloading mosestokenizer-1.2.1.tar.gz (37 kB)\n",
            "Collecting subword-nmt\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from mosestokenizer) (0.6.2)\n",
            "Collecting openfile\n",
            "  Downloading openfile-0.0.7-py3-none-any.whl (2.4 kB)\n",
            "Collecting uctools\n",
            "  Downloading uctools-1.3.0.tar.gz (4.6 kB)\n",
            "Collecting toolwrapper\n",
            "  Downloading toolwrapper-2.1.0.tar.gz (3.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from subword-nmt) (4.64.0)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.7/dist-packages (from subword-nmt) (4.0.3)\n",
            "Building wheels for collected packages: mosestokenizer, toolwrapper, uctools\n",
            "  Building wheel for mosestokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mosestokenizer: filename=mosestokenizer-1.2.1-py3-none-any.whl size=49189 sha256=9741d3cd4a6661382f13d4db944ee3f6b5e55ca224e41d66c4aa9994abc2905b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/35/f7/af1258779a0b890abc3c79481460c597cb1f3659d0603cfb9d\n",
            "  Building wheel for toolwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-py3-none-any.whl size=3353 sha256=e796bb7b15608e32b786d6a2dfcdb467b825c47139347fe7e8588e3854791ce8\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/4f/33/54741ffe08e38ececb1d28068a153729b4fe820bafa0a0691f\n",
            "  Building wheel for uctools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uctools: filename=uctools-1.3.0-py3-none-any.whl size=6161 sha256=82e405548719cb26bef3e35d7049f7920352980a97bd07e2b28265bf5d449f6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/44/e9/914cf8fa71f0141f9314f862538d1218fcf2b94542a0fb7d35\n",
            "Successfully built mosestokenizer toolwrapper uctools\n",
            "Installing collected packages: uctools, toolwrapper, openfile, subword-nmt, mosestokenizer\n",
            "Successfully installed mosestokenizer-1.2.1 openfile-0.0.7 subword-nmt-0.3.8 toolwrapper-2.1.0 uctools-1.3.0\n",
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 31308, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 31308 (delta 28), reused 79 (delta 24), pack-reused 31218\u001b[K\n",
            "Receiving objects: 100% (31308/31308), 21.58 MiB | 29.43 MiB/s, done.\n",
            "Resolving deltas: 100% (23061/23061), done.\n",
            "/content/fairseq\n",
            "Processing /content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+1ab7a75) (0.11.0+cu113)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+1ab7a75) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+1ab7a75) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+1ab7a75) (0.29.28)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+1ab7a75) (4.64.0)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+1ab7a75) (2.0.0)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+1ab7a75) (1.15.0)\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-2.5.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[K     |████████████████████████████████| 236 kB 42.1 MB/s \n",
            "\u001b[?25hCollecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+1ab7a75) (1.11.0+cu113)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+1ab7a75) (5.7.1)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 75.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+1ab7a75) (4.2.0)\n",
            "Collecting PyYAML>=5.1.*\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+1ab7a75) (0.4.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+1ab7a75) (0.8.9)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+1ab7a75) (2.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+1ab7a75) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+1ab7a75) (3.8.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-1.0.0a0+1ab7a75-cp37-cp37m-linux_x86_64.whl size=15346359 sha256=b6f38c1d0a8fc174bd8e1a76c3015cbca01b46048c9208348085bcc0fbda6912\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fl9dwr92/wheels/7c/35/80/edbd520a1a7e615df007002aeea9f6bf5f3c8f9243e072f6ce\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=f816966b79544885f640d7913d82cc304e38447976e6290585466963c279fd2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, omegaconf, antlr4-python3-runtime, hydra-core, bitarray, fairseq\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 bitarray-2.5.1 fairseq-1.0.0a0+1ab7a75 hydra-core-1.0.7 omegaconf-2.0.6\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the indictrans model\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "# downloading the indic-en model\n",
        "# !wget https://storage.googleapis.com/samanantar-public/V0.3/models/indic-en.zip\n",
        "# !unzip indic-en.zip\n",
        "\n",
        "# downloading the en-indic model\n",
        "!wget https://storage.googleapis.com/samanantar-public/V0.3/models/en-indic.zip\n",
        "!unzip en-indic.zip\n",
        "\n",
        "# # downloading the indic-indic model\n",
        "# !wget https://storage.googleapis.com/samanantar-public/V0.3/models/m2m.zip\n",
        "# !unzip m2m.zip\n",
        "\n",
        "%cd indicTrans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p9_ehMKYa36",
        "outputId": "fb2f312a-ba08-42fc-ebac-aa194803a415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2022-05-11 19:25:19--  https://storage.googleapis.com/samanantar-public/V0.3/models/en-indic.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.197.128, 74.125.142.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4811880516 (4.5G) [application/zip]\n",
            "Saving to: ‘en-indic.zip’\n",
            "\n",
            "en-indic.zip        100%[===================>]   4.48G  80.8MB/s    in 55s     \n",
            "\n",
            "2022-05-11 19:26:14 (83.7 MB/s) - ‘en-indic.zip’ saved [4811880516/4811880516]\n",
            "\n",
            "Archive:  en-indic.zip\n",
            "   creating: en-indic/\n",
            "   creating: en-indic/vocab/\n",
            "  inflating: en-indic/vocab/bpe_codes.32k.SRC  \n",
            "  inflating: en-indic/vocab/vocab.SRC  \n",
            "  inflating: en-indic/vocab/vocab.TGT  \n",
            "  inflating: en-indic/vocab/bpe_codes.32k.TGT  \n",
            "   creating: en-indic/final_bin/\n",
            "  inflating: en-indic/final_bin/preprocess.log  \n",
            "  inflating: en-indic/final_bin/dict.TGT.txt  \n",
            "  inflating: en-indic/final_bin/test.SRC-TGT.SRC.idx  \n",
            "  inflating: en-indic/final_bin/test.SRC-TGT.TGT.idx  \n",
            "  inflating: en-indic/final_bin/train.SRC-TGT.SRC.idx  \n",
            "  inflating: en-indic/final_bin/dict.SRC.txt  \n",
            "  inflating: en-indic/final_bin/valid.SRC-TGT.TGT.idx  \n",
            "  inflating: en-indic/final_bin/test.SRC-TGT.TGT.bin  \n",
            "  inflating: en-indic/final_bin/valid.SRC-TGT.TGT.bin  \n",
            "  inflating: en-indic/final_bin/train.SRC-TGT.TGT.idx  \n",
            "  inflating: en-indic/final_bin/train.SRC-TGT.TGT.bin  \n",
            "  inflating: en-indic/final_bin/valid.SRC-TGT.SRC.idx  \n",
            "  inflating: en-indic/final_bin/train.SRC-TGT.SRC.bin  \n",
            "  inflating: en-indic/final_bin/valid.SRC-TGT.SRC.bin  \n",
            "  inflating: en-indic/final_bin/test.SRC-TGT.SRC.bin  \n",
            "   creating: en-indic/model/\n",
            "  inflating: en-indic/model/checkpoint_best.pt  \n",
            "/content/indicTrans\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/libindic/indic-trans.git\n",
        "\n",
        "%cd indic-trans\n",
        "!pip install -r requirements.txt\n",
        "!pip install --use-feature=in-tree-build ./\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqhOQZY1hUBi",
        "outputId": "6f8c1654-266f-4867-e228-c374a7a106ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'indic-trans'...\n",
            "remote: Enumerating objects: 2214, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 2214 (delta 2), reused 6 (delta 1), pack-reused 2206\u001b[K\n",
            "Receiving objects: 100% (2214/2214), 516.51 MiB | 19.49 MiB/s, done.\n",
            "Resolving deltas: 100% (1096/1096), done.\n",
            "Checking out files: 100% (719/719), done.\n",
            "/content/indic-trans\n",
            "Collecting pbr\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.16.0)\n",
            "Requirement already satisfied: cython>=0.24.0a0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.29.28)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.4.1)\n",
            "Installing collected packages: pbr\n",
            "Successfully installed pbr-5.9.0\n",
            "Processing /content/indic-trans\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython>=0.24.0a0 in /usr/local/lib/python3.7/dist-packages (from indictrans==1.2.3) (0.29.28)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from indictrans==1.2.3) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from indictrans==1.2.3) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from indictrans==1.2.3) (1.15.0)\n",
            "Requirement already satisfied: pbr in /usr/local/lib/python3.7/dist-packages (from indictrans==1.2.3) (5.9.0)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from indictrans==1.2.3) (1.4.1)\n",
            "Building wheels for collected packages: indictrans\n",
            "  Building wheel for indictrans (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for indictrans: filename=indictrans-1.2.3-cp37-cp37m-linux_x86_64.whl size=337574804 sha256=f5b1ed573db3dc2e16f97ea43efd31bbd1e2f6e3e8e6d4ffdcefddfba77407b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/d6/75/3af977ac266f07d63ee389fb1b4cec05f78cfede0ea5717f90\n",
            "Successfully built indictrans\n",
            "Installing collected packages: indictrans\n",
            "Successfully installed indictrans-1.2.3\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from indictrans import Transliterator\n",
        "trn = Transliterator(source='eng', target='hin')\n"
      ],
      "metadata": {
        "id": "wDILhgk_hnEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8DH0P5j_Yed3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/iTOP/data/common_words_en_hi.txt\",  delimiter='\\t',names=['English', 'hi_transliterate', \"Count\"], header=None)"
      ],
      "metadata": {
        "id": "zr6BqRt9dSC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Pb3XWMXKdeVp",
        "outputId": "cbc6dcbd-826b-48d7-e63e-96324f793720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       English hi_transliterate  Count\n",
              "0        alarm           अलार्म  704.0\n",
              "1          set              सेट  499.0\n",
              "2      weekend           वीकेंड  133.0\n",
              "3      chicken             चिकन  120.0\n",
              "4           10               10  115.0\n",
              "...        ...              ...    ...\n",
              "1983  omelette            ऑमलेट    1.0\n",
              "1984      oreo            ओरियो    1.0\n",
              "1985  frosting       फ्रॉस्टिंग    1.0\n",
              "1986    string         स्ट्रिंग    1.0\n",
              "1987       400              400    1.0\n",
              "\n",
              "[1988 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce6a521c-2f6f-4537-836c-9ecdd5ba3387\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>hi_transliterate</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>alarm</td>\n",
              "      <td>अलार्म</td>\n",
              "      <td>704.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>set</td>\n",
              "      <td>सेट</td>\n",
              "      <td>499.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>weekend</td>\n",
              "      <td>वीकेंड</td>\n",
              "      <td>133.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chicken</td>\n",
              "      <td>चिकन</td>\n",
              "      <td>120.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>115.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1983</th>\n",
              "      <td>omelette</td>\n",
              "      <td>ऑमलेट</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1984</th>\n",
              "      <td>oreo</td>\n",
              "      <td>ओरियो</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1985</th>\n",
              "      <td>frosting</td>\n",
              "      <td>फ्रॉस्टिंग</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986</th>\n",
              "      <td>string</td>\n",
              "      <td>स्ट्रिंग</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1987</th>\n",
              "      <td>400</td>\n",
              "      <td>400</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1988 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce6a521c-2f6f-4537-836c-9ecdd5ba3387')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce6a521c-2f6f-4537-836c-9ecdd5ba3387 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce6a521c-2f6f-4537-836c-9ecdd5ba3387');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/indicTrans\n",
        "!ls\n",
        "from indicTrans.inference.engine import Model\n",
        "\n",
        "en2indic_model = Model(expdir='../en-indic')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KCyEmSzfq9l",
        "outputId": "fc80fa87-31bb-4339-fe78-800f98eac681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/indicTrans\n",
            "api\t\t\t\t\tjoint_score.sh\n",
            "apply_bpe_traindevtest_notag.sh\t\tjoint_translate.sh\n",
            "apply_single_bpe_traindevtest_notag.sh\tlearn_bpe.sh\n",
            "binarize_training_exp.sh\t\tlearn_single_bpe.sh\n",
            "compute_bleu.sh\t\t\t\tlegacy\n",
            "indic_nlp_library\t\t\tLICENSE\n",
            "indic_nlp_resources\t\t\tmodel_configs\n",
            "indictrans_fairseq_inference.ipynb\tprepare_data_joint_training.sh\n",
            "indicTrans_Finetuning.ipynb\t\tprepare_data.sh\n",
            "indicTrans_python_interface.ipynb\tREADME.md\n",
            "IndicTrans_training.ipynb\t\tscripts\n",
            "inference\t\t\t\tsubword-nmt\n",
            "interface\n",
            "Initializing vocab and bpe\n",
            "Initializing model for translation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-11 19:30:30 | INFO | fairseq.tasks.translation | [SRC] dictionary: 32104 types\n",
            "2022-05-11 19:30:30 | INFO | fairseq.tasks.translation | [TGT] dictionary: 35888 types\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INDIC = [\"as\", \"bn\", \"gu\", \"kn\", \"ml\", \"mr\", \"or\", \"pa\", \"ta\", \"te\"]\n",
        "TRANS = [\"asm\", \"ben\", \"guj\", \"kan\", \"mal\", \"mar\", \"ori\", \"pan\", \"tam\", \"tel\"]"
      ],
      "metadata": {
        "id": "aUD0R4QzfchV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['hi_translate'] = en2indic_model.batch_translate(df['English'].apply(str).to_list(), 'en', 'hi')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q54KQk9JdeoY",
        "outputId": "dc24a7be-7638-4d7f-b583-aa14816ff669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1988/1988 [00:00<00:00, 4196.61it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, lang in enumerate(INDIC):\n",
        "  df[f'{lang}_translate'] = en2indic_model.batch_translate(df['English'].apply(str).to_list(), 'en', lang)\n",
        "  r2h = Transliterator(source='eng', target=TRANS[idx])\n",
        "  df[f'{lang}_transliterate'] = list(map(r2h.transform, df['English'].apply(str).to_list()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8QiQgC_ftbb",
        "outputId": "aab0ebf2-8764-4b96-c345-ceaea8cc05ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1988/1988 [00:00<00:00, 4321.03it/s]\n",
            "100%|██████████| 1988/1988 [00:00<00:00, 9773.98it/s]\n",
            "100%|██████████| 1988/1988 [00:00<00:00, 9952.10it/s]\n",
            "100%|██████████| 1988/1988 [00:00<00:00, 9392.91it/s]\n",
            "100%|██████████| 1988/1988 [00:00<00:00, 8900.98it/s]\n",
            "100%|██████████| 1988/1988 [00:00<00:00, 9266.69it/s]\n",
            "100%|██████████| 1988/1988 [00:00<00:00, 8922.11it/s]\n",
            "100%|██████████| 1988/1988 [00:00<00:00, 8641.52it/s]\n",
            "100%|██████████| 1988/1988 [00:00<00:00, 9417.93it/s]\n",
            "100%|██████████| 1988/1988 [00:00<00:00, 10074.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/iTOP/data/transliterations_data.csv',index=False)"
      ],
      "metadata": {
        "id": "jMqJfD93kxXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/iTOP/data/transliterations_data.csv')"
      ],
      "metadata": {
        "id": "_1GzqR1xq2DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "eVfyqnf0k8o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/iTOP/data/indic-TOP/hi.json\",\"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKyteUhioZ9t",
        "outputId": "afbaf430-ebde-4df6-8bcc-96dc9b465e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train', 'validation', 'test'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')\n",
        "from nltk.corpus import words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUupi-C_occu",
        "outputId": "ba16036e-6181-461c-9a4a-3edd54f6ad94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INDIC = [\"hi\",\"as\", \"bn\", \"gu\", \"kn\", \"ml\", \"mr\", \"or\", \"pa\", \"ta\", \"te\"]\n",
        "TRANS = [\"hin\",\"asm\", \"ben\", \"guj\", \"kan\", \"mal\", \"mar\", \"ori\", \"pan\", \"tam\", \"tel\"]"
      ],
      "metadata": {
        "id": "5lGcUJewsmRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"आशना के School से एलेक्स सेंट के पास संगीत समारोह में जाने का सबसे आसान तरीका ढूंढें।\"\n",
        "\n",
        "def post_process(sent, lang):\n",
        "\n",
        "  tokens = sent.split()\n",
        "  translations = df[f'{lang}_translate'].apply(str).to_list()\n",
        "  transliterations = df[f'{lang}_transliterate'].apply(str).to_list()\n",
        "\n",
        "  new_toks = []\n",
        "  for tok in tokens:\n",
        "    # if tok in words.words():\n",
        "    #   tok = r2h.transform(tok)\n",
        "    if str(tok) in translations:\n",
        "      tok = transliterations[translations.index(str(tok))]\n",
        "\n",
        "    new_toks.append(tok)\n",
        "\n",
        "  return ' '.join(new_toks)\n",
        "\n"
      ],
      "metadata": {
        "id": "Z0B11RczpAFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# r2h = Transliterator(source='eng', target=TRANS[INDIC.index(\"hi\")])\n",
        "post_process(sent,\"hi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "mNXAR4j2rvjx",
        "outputId": "bf8ada38-ef98-438f-8789-535fc8296937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5c47e5ec48c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr2h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransliterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eng'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRANS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mINDIC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Transliterator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "for lang in INDIC:\n",
        "  print(lang)\n",
        "  r2h = Transliterator(source='eng', target=TRANS[INDIC.index(lang)])\n",
        "  with open(f\"/content/drive/MyDrive/iTOP/data/indic-TOP/{lang}.json\",\"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  for ent in tqdm(data['train']):\n",
        "    ent['postprocessed_translated_question'] = post_process(ent['translated question'],lang)\n",
        "\n",
        "  for ent in tqdm(data['validation']):\n",
        "    ent['postprocessed_translated_question'] = post_process(ent['translated question'],lang)\n",
        "\n",
        "  for ent in tqdm(data['test']):\n",
        "    ent['postprocessed_translated_question'] = post_process(ent['translated question'],lang)\n",
        "\n",
        "  with open(f\"/content/drive/MyDrive/iTOP/data/indic-TOP/{lang}.json\",\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(data,f,indent=6, ensure_ascii=False)\n"
      ],
      "metadata": {
        "id": "AbpdCg89sfqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"/content/drive/MyDrive/iTOP/data/itop/hi.json\",\"r\") as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOnXUtkbuXxN",
        "outputId": "1326d2e9-32fc-483d-a88c-a4df4d7fc477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train', 'validation', 'test'])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'][0].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilQVFRNW9rcr",
        "outputId": "2d66eb07-5868-4d61-d3fa-7fdf3e593dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['idx', 'intent', 'spans', 'question', 'domain', 'lang', 'logical_form', 'tokenized_question', 'processed question', 'translated question'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "for lang in INDIC:\n",
        "  print(lang)\n",
        "  with open(f\"/content/drive/MyDrive/iTOP/data/itop/{lang}.json\",\"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  for ent in tqdm(data['train']):\n",
        "    ent['postprocessed_translated_question'] = post_process(ent['translated question'],lang)\n",
        "\n",
        "  for ent in tqdm(data['validation']):\n",
        "    ent['postprocessed_translated_question'] = post_process(ent['translated question'],lang)\n",
        "\n",
        "  for ent in tqdm(data['test']):\n",
        "    ent['postprocessed_translated_question'] = post_process(ent['translated question'],lang)\n",
        "\n",
        "  with open(f\"/content/drive/MyDrive/iTOP/data/itop/{lang}.json\",\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(data, f, indent=6, ensure_ascii=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPtJhXxSuJKJ",
        "outputId": "a0c6a4bf-4331-49eb-bf42-919c63c6a238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi\n",
            "as\n",
            "bn\n",
            "gu\n",
            "kn\n",
            "ml\n",
            "mr\n",
            "or\n",
            "pa\n",
            "ta\n",
            "te\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"/content/drive/MyDrive/iTOP/data/indic-atis/hi.json\",\"r\") as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVPeHyWX_SVj",
        "outputId": "134c57d5-ce01-43bb-b033-ed204f311c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train', 'test'])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'][0].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THW5G5omLEEp",
        "outputId": "b489a622-ac40-473e-fefd-d12d3f2ff050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['text', 'intent', 'entities', 'translated text', 'logical form'])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in INDIC:\n",
        "  print(lang)\n",
        "  with open(f\"/content/drive/MyDrive/iTOP/data/indic-atis/{lang}.json\",\"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  for ent in data['train']:\n",
        "    ent['postprocessed_translated_text'] = post_process(ent['text'],lang)\n",
        "\n",
        "\n",
        "  for ent in data['test']:\n",
        "    ent['postprocessed_translated_text'] = post_process(ent['text'],lang)\n",
        "\n",
        "  with open(f\"/content/drive/MyDrive/iTOP/data/indic-atis/{lang}.json\",\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(data, f, indent=6, ensure_ascii=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0RdtIEAvhx4",
        "outputId": "cd6019f7-f17b-4bc2-9625-e0ab71493821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi\n",
            "as\n",
            "bn\n",
            "gu\n",
            "kn\n",
            "ml\n",
            "mr\n",
            "or\n",
            "pa\n",
            "ta\n",
            "te\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uwKPCp00AIR_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}