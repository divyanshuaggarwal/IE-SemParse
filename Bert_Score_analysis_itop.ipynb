{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xoaC2Vj4uHjW"
   },
   "outputs": [],
   "source": [
    "!pip install evaluate datasets bert_score -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BYK4qIBpJbP4"
   },
   "outputs": [],
   "source": [
    "# !wget https://ai4b-my.sharepoint.com/:u:/g/personal/sumanthdoddapaneni_ai4bharat_org/EXhX84sbTQhLrsURCU9DlUwBVyJ10cYK9bQQe1SMljf_yA?download=1 -c -O 'v3.zip'\n",
    "# !unzip v3.zip -d samanantar\n",
    "# !rm -rf v3.zip\n",
    "\n",
    "\n",
    "# %cd /content/samanantar/v2/en-te\n",
    "\n",
    "# !rm -R -- */\n",
    "\n",
    "# %cd /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HlnzC4Lcs5mX"
   },
   "outputs": [],
   "source": [
    "# # clone the repo for running evaluation\n",
    "# !git clone https://github.com/AI4Bharat/indicTrans.git\n",
    "# %cd indicTrans\n",
    "# # clone requirements repositories\n",
    "# !git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git\n",
    "# !git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
    "# !git clone https://github.com/rsennrich/subword-nmt.git\n",
    "# %cd ..\n",
    "\n",
    "\n",
    "# # Install the necessary libraries\n",
    "# !pip install sacremoses pandas mock sacrebleu tensorboardX pyarrow indic-nlp-library\n",
    "# ! pip install mosestokenizer subword-nmt\n",
    "# # Install fairseq from source\n",
    "# !git clone https://github.com/pytorch/fairseq.git\n",
    "# %cd fairseq\n",
    "# # !git checkout da9eaba12d82b9bfc1442f0e2c6fc1b895f4d35d\n",
    "# !pip install ./\n",
    "# ! pip install xformers\n",
    "# %cd ..\n",
    "\n",
    "\n",
    "# # add fairseq folder to python path\n",
    "# import os\n",
    "# os.environ['PYTHONPATH'] += \":/content/fairseq/\"\n",
    "# # sanity check to see if fairseq is installed\n",
    "# from fairseq import checkpoint_utils, distributed_utils, options, tasks, utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "knB_wSAZptLi"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # download the indictrans model\n",
    "\n",
    "# %cd /content/\n",
    "# # downloading the indic-en model\n",
    "# !wget https://ai4b-my.sharepoint.com/:u:/g/personal/sumanthdoddapaneni_ai4bharat_org/ETnq-z4aHXFAjDF1Te3AZ20BaZ59PwlKlzSemEHhrmYJ3w?download=1 -c -O 'indic-en.zip'\n",
    "# !unzip indic-en.zip\n",
    "# !rm -rf indic-en.zip\n",
    "\n",
    "# # downloading the en-indic model\n",
    "# # !wget https://storage.googleapis.com/samanantar-public/V0.3/models/en-indic.zip\n",
    "# # !unzip en-indic.zip\n",
    "\n",
    "# # # downloading the indic-indic model\n",
    "# # !wget https://storage.googleapis.com/samanantar-public/V0.3/models/m2m.zip\n",
    "# # !unzip m2m.zip\n",
    "\n",
    "# %cd /content/indicTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-4L_xpeME7u8"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir(\"/content/indicTrans\")\n",
    "# from indicTrans.inference.engine import Model\n",
    "\n",
    "# indic2en_model = Model(expdir='../indic-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mT2QitleHclt"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae74b6f17df499c9e38a32248dcb514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets, evaluate\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "# comet = evaluate.load(\"comet\", \"wmt21-comet-qe-mqm\", show_progress = True, cuda = torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BuUrGoAD4yTJ"
   },
   "outputs": [],
   "source": [
    "# comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-SzAQAfG12z",
    "outputId": "e9903fd0-40c9-4a07-d6f8-f7255c8c4d48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"bert_score\", module_type: \"metric\", features: [{'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id='references')}, {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}], usage: \"\"\"\n",
       "BERTScore Metrics with the hashcode from a source against one or more references.\n",
       "\n",
       "Args:\n",
       "    predictions (list of str): Prediction/candidate sentences.\n",
       "    references (list of str or list of list of str): Reference sentences.\n",
       "    lang (str): Language of the sentences; required (e.g. 'en').\n",
       "    model_type (str): Bert specification, default using the suggested\n",
       "        model for the target language; has to specify at least one of\n",
       "        `model_type` or `lang`.\n",
       "    num_layers (int): The layer of representation to use,\n",
       "        default using the number of layers tuned on WMT16 correlation data.\n",
       "    verbose (bool): Turn on intermediate status update.\n",
       "    idf (bool or dict): Use idf weighting; can also be a precomputed idf_dict.\n",
       "    device (str): On which the contextual embedding model will be allocated on.\n",
       "        If this argument is None, the model lives on cuda:0 if cuda is available.\n",
       "    nthreads (int): Number of threads.\n",
       "    batch_size (int): Bert score processing batch size,\n",
       "        at least one of `model_type` or `lang`. `lang` needs to be\n",
       "        specified when `rescale_with_baseline` is True.\n",
       "    rescale_with_baseline (bool): Rescale bertscore with pre-computed baseline.\n",
       "    baseline_path (str): Customized baseline file.\n",
       "    use_fast_tokenizer (bool): `use_fast` parameter passed to HF tokenizer. New in version 0.3.10.\n",
       "\n",
       "Returns:\n",
       "    precision: Precision.\n",
       "    recall: Recall.\n",
       "    f1: F1 score.\n",
       "    hashcode: Hashcode of the library.\n",
       "\n",
       "Examples:\n",
       "\n",
       "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
       "    >>> references = [\"hello there\", \"general kenobi\"]\n",
       "    >>> bertscore = evaluate.load(\"bertscore\")\n",
       "    >>> results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
       "    >>> print([round(v, 2) for v in results[\"f1\"]])\n",
       "    [1.0, 1.0]\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BfRMURcNNRT8"
   },
   "outputs": [],
   "source": [
    "def sample_sentences(lang, num = 100000):\n",
    "    with open(f\"/content/samanantar/v2/en-{lang}/train.en\") as en_f, open(f\"/content/samanantar/v2/en-{lang}/train.{lang}\") as ind_f:\n",
    "        sents = random.sample([(en, ind) for ind, en in zip(ind_f.readlines(), en_f.readlines())], num)\n",
    "    \n",
    "    outs = {\n",
    "        \"indic\": [sent[1] for sent in sents],\n",
    "        \"english\": [sent[0] for sent in sents]\n",
    "    }\n",
    "    return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dPa_q9R0vTcj"
   },
   "outputs": [],
   "source": [
    "# from comet import download_model, load_from_checkpoint\n",
    "\n",
    "# model_path = download_model(\"wmt21-comet-qe-mqm\")\n",
    "# comet = load_from_checkpoint(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xxmMeOt88WHo"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "INDIC = [\"as\", \"bn\", \"gu\", \"hi\", \"kn\", \"ml\", \"mr\", \"or\", \"pa\", \"ta\", \"te\"]\n",
    "datasets = [\n",
    "    'indic-TOP',\n",
    "             'itop',\n",
    "             'indic-atis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2w8oQbLy_317"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# def comet_score_data(sents):\n",
    "#     data = {\"src\": sents[\"english\"], \"mt\": sents['indic'], \"ref\": [\"\" for _ in range(len(sents['indic']))]}\n",
    "#     data = [dict(zip(data, t)) for t in zip(*data.values())]\n",
    "#     seg_scores, avg_score = comet.predict(data, batch_size=64, gpus=1)\n",
    "#     return seg_scores, avg_score\n",
    "\n",
    "def bertscore_data(sents):\n",
    "    results = bertscore.compute(\n",
    "                                predictions=sents['indic'], \n",
    "                                references=sents['english'], \n",
    "                                model_type=\"xlm-roberta-large\", \n",
    "                                batch_size=128,\n",
    "                                use_fast_tokenizer=True\n",
    "                                )\n",
    "    return results[\"f1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KVz-ySo6-K_9"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def create_dataset(dataset, train_lang, test_lang, backtranslated=False):\n",
    "\n",
    "    if train_lang != \"en\":\n",
    "        with open(f\"Indic-SemParse/unfiltered_data/{dataset}/{train_lang}.json\", \"r\") as f:\n",
    "            train_data = json.load(f)\n",
    "\n",
    "    else:\n",
    "        with open(f\"Indic-SemParse/unfiltered_data/{dataset}/hi.json\", \"r\") as f:\n",
    "            train_data = json.load(f)\n",
    "\n",
    "    if test_lang != \"en\":\n",
    "        with open(f\"Indic-SemParse/unfiltered_data/{dataset}/{test_lang}.json\", \"r\") as f:\n",
    "            test_data = json.load(f)\n",
    "\n",
    "    else:\n",
    "        with open(f\"Indic-SemParse/unfiltered_data/{dataset}/hi.json\", \"r\") as f:\n",
    "            test_data = json.load(f)\n",
    "\n",
    "    train = train_data[\"train\"]\n",
    "\n",
    "    val = test_data[\"validation\"]\n",
    "\n",
    "    test = test_data[\"test\"]\n",
    "\n",
    "    if dataset == \"itop\":\n",
    "        for idx, example in enumerate(train):\n",
    "            if train_lang != \"en\":\n",
    "                train[idx][\"original_src\"] = example[\"question\"]\n",
    "                train[idx][\"translated_src\"] = example[\"postprocessed_translated_question\"]\n",
    "            else:\n",
    "                train[idx][\"src\"] = example[\"question\"]\n",
    "            train[idx][\"trg\"] = example[\"logical_form\"]\n",
    "\n",
    "        for idx, example in enumerate(val):\n",
    "            if test_lang != \"en\":\n",
    "                if backtranslated:\n",
    "                    val[idx][\"orig\"] = example[\"question\"]\n",
    "                    val[idx][\"src\"] = example[\"backtranslated_post_processed_questions\"]\n",
    "                else:\n",
    "                    val[idx][\"orig\"] = example[\"question\"]\n",
    "                    val[idx][\"src\"] = example[\"postprocessed_translated_question\"]\n",
    "            else:\n",
    "                val[idx][\"src\"] = example[\"question\"]\n",
    "            val[idx][\"trg\"] = example[\"logical_form\"]\n",
    "\n",
    "        for idx, example in enumerate(test):\n",
    "            if test_lang != \"en\":\n",
    "                if backtranslated:\n",
    "                    test[idx][\"orig\"] = example[\"question\"]\n",
    "                    test[idx][\"src\"] = example[\n",
    "                        \"backtranslated_post_processed_questions\"\n",
    "                    ]\n",
    "                else:\n",
    "                    test[idx][\"orig\"] = example[\"question\"]\n",
    "                    test[idx][\"src\"] = example[\"postprocessed_translated_question\"]\n",
    "            else:\n",
    "                test[idx][\"src\"] = example[\"question\"]\n",
    "            test[idx][\"trg\"] = example[\"logical_form\"]\n",
    "\n",
    "    elif dataset == \"indic-TOP\":\n",
    "        for idx, example in enumerate(train):\n",
    "            if train_lang != \"en\":\n",
    "                train[idx][\"src\"] = example[\"postprocessed_translated_question\"]\n",
    "            else:\n",
    "                train[idx][\"src\"] = example[\"question\"]\n",
    "            train[idx][\"trg\"] = example[\"decoupled logical form\"]\n",
    "\n",
    "        for idx, example in enumerate(val):\n",
    "            if test_lang != \"en\":\n",
    "                if backtranslated:\n",
    "                    val[idx][\"orig\"] = example[\"question\"]\n",
    "                    val[idx][\"src\"] = example[\"backtranslated_post_processed_questions\"]\n",
    "                else:\n",
    "                    val[idx][\"orig\"] = example[\"question\"]\n",
    "                    val[idx][\"src\"] = example[\"postprocessed_translated_question\"]\n",
    "            else:\n",
    "                val[idx][\"src\"] = example[\"question\"]\n",
    "            val[idx][\"trg\"] = example[\"decoupled logical form\"]\n",
    "\n",
    "        for idx, example in enumerate(test):\n",
    "            if test_lang != \"en\":\n",
    "                if backtranslated:\n",
    "                    test[idx][\"orig\"] = example[\"question\"]\n",
    "                    test[idx][\"src\"] = example[\n",
    "                        \"backtranslated_post_processed_questions\"\n",
    "                    ]\n",
    "                else:\n",
    "                    test[idx][\"orig\"] = example[\"question\"]\n",
    "                    test[idx][\"src\"] = example[\"postprocessed_translated_question\"]\n",
    "            else:\n",
    "                test[idx][\"src\"] = example[\"question\"]\n",
    "            test[idx][\"trg\"] = example[\"decoupled logical form\"]\n",
    "            \n",
    "\n",
    "    elif dataset == \"indic-atis\":\n",
    "        for idx, example in enumerate(train):\n",
    "            if train_lang != \"en\":\n",
    "                train[idx][\"src\"] = example[\"translated text\"]\n",
    "            else:\n",
    "                train[idx][\"src\"] = example[\"text\"]\n",
    "            train[idx][\"trg\"] = example[\"logical form\"]\n",
    "\n",
    "        for idx, example in enumerate(val):\n",
    "            if test_lang != \"en\":\n",
    "                if backtranslated:\n",
    "                    val[idx][\"orig\"] = example[\"text\"]\n",
    "                    val[idx][\"src\"] = example[\"back translated text\"]\n",
    "                else:\n",
    "                    val[idx][\"orig\"] = example[\"text\"]\n",
    "                    val[idx][\"src\"] = example[\"translated text\"]\n",
    "            else:\n",
    "                val[idx][\"src\"] = example[\"text\"]\n",
    "            val[idx][\"trg\"] = example[\"logical form\"]\n",
    "\n",
    "        for idx, example in enumerate(test):\n",
    "            if test_lang != \"en\":\n",
    "                if backtranslated:\n",
    "                    test[idx][\"orig\"] = example[\"text\"]\n",
    "                    test[idx][\"src\"] = example[\"back translated text\"]\n",
    "                else:\n",
    "                    test[idx][\"orig\"] = example[\"text\"]\n",
    "                    test[idx][\"src\"] = example[\"translated text\"]\n",
    "            else:\n",
    "                test[idx][\"src\"] = example[\"text\"]\n",
    "            test[idx][\"trg\"] = example[\"logical form\"]\n",
    "\n",
    "    train_data = Dataset.from_pandas(pd.DataFrame(data=train))\n",
    "\n",
    "    val_data = Dataset.from_pandas(pd.DataFrame(data=val))\n",
    "\n",
    "    test_data = Dataset.from_pandas(pd.DataFrame(data=test))\n",
    "\n",
    "    dataset = DatasetDict()\n",
    "\n",
    "    dataset[\"train\"] = train_data\n",
    "\n",
    "    dataset[\"val\"] = val_data\n",
    "\n",
    "    dataset[\"test\"] = test_data\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GteGypx4pZod",
    "outputId": "5ad8fe6c-5990-4fcc-b300-73f85744cc0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Show me the dates of two thousand eighteen of these concerts',\n",
       " 'Show me dates for music festivals in 2018')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_dataset(\"itop\", \"hi\", \"hi\", True)\n",
    "\n",
    "dataset['test']['src'][0], dataset['test']['orig'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4RMoG_KtqnY8"
   },
   "outputs": [],
   "source": [
    "from statistics import mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ej6GFGbIpBbS"
   },
   "outputs": [],
   "source": [
    "def bt_bertscore_data(sents):\n",
    "    results = bertscore.compute(\n",
    "                                predictions=sents['src'], \n",
    "                                references=sents['orig'], \n",
    "                                batch_size=128,\n",
    "                                lang=\"en\",\n",
    "                                use_fast_tokenizer=True,\n",
    "                                verbose=True,\n",
    "                                idf=True\n",
    "                                )\n",
    "    return mean([round(v,2) for v in results[\"f1\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "610663c7ed524c55967bf143b97d7205",
      "a2ee8153e1084fe6b26951eaa3df09cb",
      "452eacff250341a0bbb4270dbe667810",
      "2bd8e8c674cc45a9af5208781c505af7",
      "23a39c7c92dc4f5394e2455137659333",
      "13800cb000a5465081a91edc67bf8306",
      "4469d0c8da5d49388f39db487575d5eb",
      "4d272aa615cb4b84bbc76d23fbe0cd79",
      "a6cb7e6818d248fa91f10910f9982d77",
      "57344b0c3914430997104039288fc25b",
      "0ce2082090674a969cc25848840e8485"
     ]
    },
    "id": "mJhgL4JOqyAo",
    "outputId": "ce2d1da9-457b-4799-d512-1a6e3bc5ac28"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927550dac5a8478d857a059ef248e452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9964/610969268.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbt_bert_scores\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mINDIC\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mbt_bert_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbt_bertscore_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9964/2982467736.py\u001b[0m in \u001b[0;36mbt_bertscore_data\u001b[0;34m(sents)\u001b[0m\n\u001b[1;32m      7\u001b[0m                                 \u001b[0muse_fast_tokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                 \u001b[0midf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                                 )\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/evaluate/module.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtemp_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcompute_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_writer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--bertscore/cf4907b18f8f741f202232c0f8009a3bd49ff98802c245abcb6ea51a37a8c05b/bertscore.py\u001b[0m in \u001b[0;36m_compute\u001b[0;34m(self, predictions, references, lang, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0mrescale_with_baseline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrescale_with_baseline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                     \u001b[0mbaseline_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m                 )\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/bert_score/scorer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_type, num_layers, batch_size, nthreads, all_layers, idf, idf_sents, device, lang, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_fast_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_fast_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_fast_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/bert_score/utils.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(model_type, num_layers, all_layers)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5EncoderModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             return model_class.from_pretrained(\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m             )\n\u001b[1;32m    466\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2135\u001b[0m                         \u001b[0m_commit_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommit_hash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2136\u001b[0m                     )\n\u001b[0;32m-> 2137\u001b[0;31m                     \u001b[0mresolved_archive_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcached_file_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2139\u001b[0m                     \u001b[0;31m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mresume_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         )\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m             )\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1245\u001b[0m                 \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m                 \u001b[0mresume_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m             )\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetEffectiveLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     )\n\u001b[0;32m--> 495\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                 \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "bt_bert_scores = []\n",
    "\n",
    "\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    bt_bert_scores += [{\"dataset\":dataset}]\n",
    "    for lang in INDIC:\n",
    "        bt_bert_scores[i][lang] = bt_bertscore_data(create_dataset(dataset, lang, lang, True)['test'])\n",
    "\n",
    "\n",
    "pd.DataFrame(bt_bert_scores).to_csv(\"bt_bertscore_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0FGxLWWq_mB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUNrSicu75N2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "comet_scores = {}\n",
    "\n",
    "\n",
    "for lang in INDIC:\n",
    "    if \"samantar_comet_scores.json\" in os.listdir(\"/content/drive/MyDrive/iTOP/\"):\n",
    "        with open(\"/content/drive/MyDrive/iTOP/samantar_comet_scores.json\", \"r\") as f:\n",
    "            comet_scores = json.load(f)\n",
    "        if lang in comet_scores:\n",
    "            continue\n",
    "    print(lang)\n",
    "    sents = sample_sentences(lang)\n",
    "    comet_scores[lang] = round(comet_score_data(sents)[1], 3)\n",
    "    pprint(comet_scores)\n",
    "    torch.cuda.empty_cache()\n",
    "    with open(\"/content/drive/MyDrive/iTOP/samantar_comet_scores.json\", \"w\") as f:\n",
    "        json.dump(comet_scores, f, indent = 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGArfqCF-LEa"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "bert_scores = {}\n",
    "\n",
    "offset = 10000\n",
    "\n",
    "for lang in INDIC:\n",
    "    if \"samantar_bert_scores.json\" in os.listdir(\"/content/drive/MyDrive/iTOP/\"):\n",
    "        with open(\"/content/drive/MyDrive/iTOP/samantar_bert_scores.json\", \"r\") as f:\n",
    "            bert_scores = json.load(f)\n",
    "        if lang in bert_scores:\n",
    "            continue\n",
    "    print(lang)\n",
    "    scores = []\n",
    "    sents = sample_sentences(lang)\n",
    "    for idx in range(0, len(sents), offset):\n",
    "        scores += bertscore_data({k:sents[k][idx:idx+offset] for k in sents})\n",
    "    bert_scores[lang] = sum(scores)/len(scores)\n",
    "    pprint(bert_scores)\n",
    "    torch.cuda.empty_cache()\n",
    "  \n",
    "    with open(\"/content/drive/MyDrive/iTOP/samantar_bert_scores.json\", \"w\") as f:\n",
    "        json.dump(bert_scores, f, indent = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gH_XiTCe-K7i"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"/content/drive/MyDrive/iTOP/filtered_data\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g06aq4Aw-K5N"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"/content/drive/MyDrive/iTOP/filtered_data/itop\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"/content/drive/MyDrive/iTOP/filtered_data/indic-TOP\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"/content/drive/MyDrive/iTOP/filtered_data/indic-atis\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUmqlp-xWCkW"
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVCDIxdAkQgO"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"/content/drive/MyDrive/iTOP/filtered_data_2\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"/content/drive/MyDrive/iTOP/filtered_data_2/itop\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"/content/drive/MyDrive/iTOP/filtered_data_2/indic-TOP\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"/content/drive/MyDrive/iTOP/filtered_data_2/indic-atis\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "785vJqvRZNw_"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/iTOP/samantar_comet_scores.json\", \"r\") as f:\n",
    "    comet_scores = json.load(f)\n",
    "\n",
    "with open(\"/content/drive/MyDrive/iTOP/samantar_bert_scores.json\", \"r\") as f:\n",
    "    bert_scores = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUXY4gzX-K3I"
   },
   "outputs": [],
   "source": [
    "for ds in data_sets:\n",
    "    for lang in INDIC:\n",
    "        print(ds)\n",
    "        print(lang)\n",
    "        if f\"{lang}.json\" in os.listdir(f\"/content/drive/MyDrive/iTOP/filtered_data_2/{ds}\"):\n",
    "            print(\"skipping.....\")\n",
    "            continue\n",
    "\n",
    "        data  = create_dataset(ds,lang, lang)\n",
    "\n",
    "        print(\"val\")\n",
    "        dev_comet_scores = comet_score_data({\"english\": data['val']['orig'], \"indic\": data['val']['src']})[0]\n",
    "        dev_bert_scores = bertscore_data({\"english\": data['val']['orig'], \"indic\": data['val']['src']})\n",
    "\n",
    "        print(\"test\")\n",
    "        test_comet_scores = comet_score_data({\"english\": data['test']['orig'], \"indic\": data['test']['src']})[0]\n",
    "        test_bert_scores = bertscore_data({\"english\": data['test']['orig'], \"indic\": data['test']['src']})\n",
    "        \n",
    "\n",
    "        print(\"test comet Score:\", np.mean(test_comet_scores))\n",
    "        print(\"test bert Score:\", np.mean(test_bert_scores))\n",
    "        \n",
    "\n",
    "        new_data = DatasetDict()\n",
    "\n",
    "        new_data['train'] = data['train']\n",
    "        new_data['val'] = data['val'].select(indices=[idx for idx in range(len(data['val'])) \n",
    "                                                        if dev_comet_scores[idx] >= 0.9*comet_scores[lang] and \n",
    "                                                            dev_bert_scores[idx] >= 0.9*bert_scores[lang]])\n",
    "        \n",
    "        new_data['test'] = data['test'].select(indices=[idx for idx in range(len(data['test'])) \n",
    "                                                        if test_comet_scores[idx] >= 0.9*comet_scores[lang] and \n",
    "                                                            test_bert_scores[idx] >= 0.9*bert_scores[lang]])\n",
    "        \n",
    "\n",
    "        print(new_data)\n",
    "        data_save = {k:new_data[k].to_pandas() for k in new_data.keys()}\n",
    "        if ds == \"indic-atis\":\n",
    "            \n",
    "            data_save['train']['entities'] = list(map(json.dumps, list(map(list,new_data['train'].to_pandas()['entities'].to_list()))))\n",
    "            data_save['val']['entities'] = list(map(json.dumps, list(map(list,new_data['val'].to_pandas()['entities'].to_list()))))\n",
    "            data_save['test']['entities'] = list(map(json.dumps, list(map(list,new_data['test'].to_pandas()['entities'].to_list()))))\n",
    "\n",
    "        with open(f\"/content/drive/MyDrive/iTOP/filtered_data/{ds}/{lang}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({k:data_save[k].to_dict(\"records\") for k in data_save}, f, indent=6, ensure_ascii=False)\n",
    "\n",
    "        # else:\n",
    "        #     with open(f\"/content/drive/MyDrive/iTOP/filtered_data/{ds}/{lang}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        #         json.dump({k:new_data[k].to_pandas().to_dict(\"records\") for k in data_save}, f, indent=6, ensure_ascii=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4yPt9oLXBtZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0ce2082090674a969cc25848840e8485": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13800cb000a5465081a91edc67bf8306": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23a39c7c92dc4f5394e2455137659333": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bd8e8c674cc45a9af5208781c505af7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57344b0c3914430997104039288fc25b",
      "placeholder": "",
      "style": "IPY_MODEL_0ce2082090674a969cc25848840e8485",
      "value": " 112/137 [04:59&lt;03:04,  7.38s/it]"
     }
    },
    "4469d0c8da5d49388f39db487575d5eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "452eacff250341a0bbb4270dbe667810": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d272aa615cb4b84bbc76d23fbe0cd79",
      "max": 137,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6cb7e6818d248fa91f10910f9982d77",
      "value": 112
     }
    },
    "4d272aa615cb4b84bbc76d23fbe0cd79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57344b0c3914430997104039288fc25b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "610663c7ed524c55967bf143b97d7205": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a2ee8153e1084fe6b26951eaa3df09cb",
       "IPY_MODEL_452eacff250341a0bbb4270dbe667810",
       "IPY_MODEL_2bd8e8c674cc45a9af5208781c505af7"
      ],
      "layout": "IPY_MODEL_23a39c7c92dc4f5394e2455137659333"
     }
    },
    "a2ee8153e1084fe6b26951eaa3df09cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13800cb000a5465081a91edc67bf8306",
      "placeholder": "",
      "style": "IPY_MODEL_4469d0c8da5d49388f39db487575d5eb",
      "value": " 82%"
     }
    },
    "a6cb7e6818d248fa91f10910f9982d77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
